{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"OHLCV Analysis\").getOrCreate()\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of bucket that contains market data parquet files\n",
    "data_path = \"gs://rzbk-stockdata/\"\n",
    "\n",
    "# Read prices parquet file into a DataFrame (OHLCV market data)\n",
    "parquet_file_path = f\"{data_path}sharadar.sep.parquet\"\n",
    "df = spark.read.parquet(parquet_file_path)\n",
    "\n",
    "# Read ticker metadata file into a Dataframe (company information)\n",
    "parquet_file_path = f\"{data_path}sharadar.tickers.parquet\"\n",
    "df_t = spark.read.parquet(parquet_file_path)\n",
    "df_t = df_t.withColumnRenamed('ticker', 'ticker2')\n",
    "for col in [column for column in df_t.columns if column not in ['exchange', ',currency', 'category', 'sector', 'industry', 'ticker2']]:\n",
    "    df_t = df_t.drop(col)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes and drop right-hand join col\n",
    "df = df.alias(\"df\").join(\n",
    "    df_t.alias(\"df2\"), \n",
    "    (F.col(\"df.ticker\") == F.col(\"df2.ticker2\")), \n",
    "    how=\"inner\"\n",
    ")\n",
    "df = df.drop(\"ticker2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define windows for processing\n",
    "win = Window.partitionBy(\"ticker\").orderBy(\"date\")\n",
    "win2 = Window.partitionBy(\"ticker\").orderBy(\"date\").rowsBetween(1, 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RSI calculation function for adding RSI cols\n",
    "def add_rsi(df, price_column, win, period=14):\n",
    "    # Calculate price difference\n",
    "    price_diff = F.col(price_column) - F.lag(F.col(price_column), 1).over(win)\n",
    "\n",
    "    # Calculate gains and losses\n",
    "    gains = F.when(price_diff > 0, price_diff).otherwise(0)\n",
    "    losses = F.when(price_diff < 0, -price_diff).otherwise(0)\n",
    "\n",
    "    # Calculate average gains and average losses over the specified period\n",
    "    win_mod = win.rowsBetween(-period, -1)\n",
    "    avg_gains = F.avg(gains).over(win_mod)\n",
    "    avg_losses = F.avg(losses).over(win_mod)\n",
    "\n",
    "    # Calculate relative strength (RS)\n",
    "    rs = avg_gains / avg_losses\n",
    "\n",
    "    # Calculate the RSI\n",
    "    rsi = F.when(avg_losses != 0, 100 - (100 / (1 + rs))).otherwise(100)\n",
    "\n",
    "    # Add the RSI column to the DataFrame\n",
    "    result_df = df.withColumn(f\"rsi{period}_rel\", rsi / 100)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "# Calculate SMA for price or volume average cols\n",
    "def add_sma(df, column, win, num_days, add_indicator=False):\n",
    "    window_spec = win.rowsBetween((-1*num_days), 0)\n",
    "    if add_indicator:\n",
    "        df = df.withColumn(f'sma_{column}_{num_days}', F.avg(F.col(column)).over(window_spec))\n",
    "    return df.withColumn(f'sma_{column}_{num_days}_rel', (F.col(column) - F.avg(F.col(column)).over(window_spec)) / F.avg(F.col(column)).over(window_spec))\n",
    "\n",
    "\n",
    "# Calculate volatility by calculating absolute percentage diff between low and high\n",
    "def add_price_range(df, win):\n",
    "    return df.withColumn('price_range', (F.col('high') - F.col('low')) / F.col('low'))    \n",
    "\n",
    "\n",
    "# Add indicators to sep data\n",
    "df = add_rsi(df, \"close\", win, 14)\n",
    "df = add_rsi(df, \"close\", win, 28)\n",
    "df = add_sma(df, \"close\", win, 5)\n",
    "df = add_sma(df, \"close\", win, 10)\n",
    "df = add_sma(df, \"close\", win, 50, add_indicator=True)\n",
    "df = add_sma(df, \"close\", win, 80)\n",
    "df = add_sma(df, \"close\", win, 200, add_indicator=True)\n",
    "df = add_sma(df, \"volume\", win, 10)\n",
    "df = add_sma(df, \"volume\", win, 50)\n",
    "df = add_sma(df, \"volume\", win, 100)\n",
    "df = add_price_range(df, win)\n",
    "df = add_sma(df, \"price_range\", win, 5, add_indicator=True)\n",
    "df = add_sma(df, \"price_range\", win, 30, add_indicator=True)\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add additional trend columns on moving averages for closing price\n",
    "df = df.withColumn(\"sma_close_50_trend\", (F.col(\"sma_close_50\") - F.lag(\"sma_close_50\").over(win)) / F.lag(\"sma_close_50\").over(win) * 100)\n",
    "df = df.withColumn(\"sma_close_200_trend\", (F.col(\"sma_close_200\") - F.lag(\"sma_close_200\").over(win)) / F.lag(\"sma_close_200\").over(win) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define entry point as when the smoothed-out price dips \n",
    "df = df.withColumn(\"Buy\", (F.col(\"low\") <= 0.85 * F.col(\"sma_close_50\")).cast(\"int\"))\n",
    "df = df.withColumn(\"Result\", (\n",
    "        (F.col(\"Buy\") == True )\n",
    "        & (F.max('high').over(win2) >= F.col(\"close\") * 1.15)\n",
    "        & (F.min('low').over(win2) >= F.col(\"close\") * 0.15)\n",
    "    ).cast(\"int\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out irrelevant data (most data)\n",
    "df = df.filter(F.col(\"Buy\") == 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data back to parquet file as a checkpoint\n",
    "df.write.parquet(f\"{data_path}sma_dip_strat.parquet\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
